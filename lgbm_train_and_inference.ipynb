{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import Booster\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_0_4_PATH = \"train_0_4.pkl\"\n",
    "TRAIN_5_12_PATH = \"train_5_12.pkl\"\n",
    "TRAIN_13_22_PATH = \"train_13_22.pkl\"\n",
    "TRAIN_LABELS_PATH = \"train_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_0_4 = pd.read_pickle(TRAIN_0_4_PATH)\n",
    "train_raw_5_12 = pd.read_pickle(TRAIN_5_12_PATH)\n",
    "train_raw_13_22 = pd.read_pickle(TRAIN_13_22_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv(TRAIN_LABELS_PATH)\n",
    "targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLS = ['level', \n",
    "            'page',\n",
    "            'hover_duration',\n",
    "            'radius_absolute_coor',\n",
    "            'tangent_absolute_coor',\n",
    "            'elapsed_time_diff']\n",
    "\n",
    "CAT_COLS = ['event_name', \n",
    "            'name', \n",
    "            'full_event_name']\n",
    "\n",
    "FULL_EVENT_NAME = {\n",
    "    \"0_4\": train_raw_0_4[\"full_event_name\"].unique().tolist(),  \n",
    "    \"5_12\": train_raw_5_12[\"full_event_name\"].unique().tolist(),  \n",
    "    \"13_22\": train_raw_13_22[\"full_event_name\"].unique().tolist()  \n",
    "}\n",
    "\n",
    "SUB_LEVELS = {'0_4': [1, 2, 3, 4],\n",
    "              '5_12': [5, 6, 7, 8, 9, 10, 11, 12],\n",
    "              '13_22': [13, 14, 15, 16, 17, 18, 19, 20, 21, 22]}\n",
    "\n",
    "\n",
    "DROP_COLS = [\"index\",\n",
    "             \"text\",\n",
    "            \"fqid\",\n",
    "            \"room_fqid\",\n",
    "            \"text_fqid\",\n",
    "            \"fullscreen\",\n",
    "            \"hq\",\n",
    "            \"music\",\n",
    "            \"level_group\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDeltaElapsedTimeFeatures(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df['elapsed_time_diff'] = df['elapsed_time'].diff(1).fillna(0)\n",
    "    df = df.drop('elapsed_time', axis=1)\n",
    "    return df\n",
    "\n",
    "def agg_by_elapsed_time_diff(col_name, iter_col, col_elapsed, feature_suffix):\n",
    "    agg = [\n",
    "        *[pl.col(col_elapsed).filter(pl.col(col_name) == c).std().alias(f\"{c}_{col_elapsed}_std_{feature_suffix}\") \n",
    "          for c in iter_col],\n",
    "        *[pl.col(col_elapsed).filter(pl.col(col_name) == c).mean().alias(f\"{c}_{col_elapsed}_mean_{feature_suffix}\") \n",
    "          for c in iter_col],\n",
    "        *[pl.col(col_elapsed).filter(pl.col(col_name) == c).sum().alias(f\"{c}_{col_elapsed}_sum_{feature_suffix}\") \n",
    "          for c in iter_col],\n",
    "        *[pl.col(col_elapsed).filter(pl.col(col_name) == c).median().alias(f\"{c}_{col_elapsed}_median_{feature_suffix}\") \n",
    "          for c in iter_col],\n",
    "        *[pl.col(col_elapsed).filter(pl.col(col_name) == c).max().alias(f\"{c}_{col_elapsed}_max_{feature_suffix}\") \n",
    "          for c in iter_col]\n",
    "    ]\n",
    "    return agg\n",
    "\n",
    "def feature_engineer_pl(x:pd.DataFrame, group, feature_suffix): \n",
    "     \n",
    "    full_event_names = FULL_EVENT_NAME[group]\n",
    "    levels = SUB_LEVELS[group]\n",
    "\n",
    "    x = pl.from_pandas(x)\n",
    "    aggs = [\n",
    "        *[pl.col(c).drop_nulls().n_unique().alias(f\"{c}_unique_{feature_suffix}\") \n",
    "          for c in CAT_COLS],\n",
    "\n",
    "        *[pl.col('level').filter(pl.col('level') == c).count().alias(f\"{c}_counts_{feature_suffix}\")\n",
    "          for c in levels],\n",
    "\n",
    "        *[pl.col(c).mean().alias(f\"{c}_mean_{feature_suffix}\") \n",
    "          for c in NUM_COLS],\n",
    "        *[pl.col(c).std().alias(f\"{c}_std_{feature_suffix}\") \n",
    "          for c in NUM_COLS],\n",
    "        *[pl.col(c).min().alias(f\"{c}_min_{feature_suffix}\") \n",
    "          for c in NUM_COLS],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max_{feature_suffix}\") \n",
    "          for c in NUM_COLS],\n",
    "        *[pl.col(c).quantile(0.25).alias(f\"{c}_q25_{feature_suffix}\") \n",
    "          for c in NUM_COLS],\n",
    "        *[pl.col(c).quantile(0.50).alias(f\"{c}_q50_{feature_suffix}\") \n",
    "          for c in NUM_COLS],\n",
    "        *[pl.col(c).quantile(0.75).alias(f\"{c}_q75_{feature_suffix}\") \n",
    "          for c in NUM_COLS]]\n",
    "    \n",
    "    aggs.extend(agg_by_elapsed_time_diff(\"full_event_name\", full_event_names, 'elapsed_time_diff', feature_suffix))\n",
    "    aggs.extend(agg_by_elapsed_time_diff(\"level\", levels, 'elapsed_time_diff',feature_suffix))\n",
    "\n",
    "    df = x.groupby(['session_id'], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "    return df.to_pandas()\n",
    "\n",
    "def createTimeFeatures(df):\n",
    "    df[\"month\"] = df[\"session_id\"].apply(lambda x: int(str(x)[2:4])+1).astype(np.uint8)\n",
    "    df[\"day\"] = df[\"session_id\"].apply(lambda x: int(str(x)[4:6])).astype(np.uint8)\n",
    "    df[\"hour\"] = df[\"session_id\"].apply(lambda x: int(str(x)[6:8])).astype(np.uint8)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df:pd.DataFrame, grp) -> pd.DataFrame:\n",
    "    df = createDeltaElapsedTimeFeatures(df)\n",
    "    df = feature_engineer_pl(df, grp, grp)\n",
    "    df = createTimeFeatures(df)\n",
    "    df = df.set_index('session_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pipeline(train_raw_0_4, \"0_4\")\n",
    "df2 = pipeline(train_raw_5_12, \"5_12\")\n",
    "df3 = pipeline(train_raw_13_22, \"13_22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train with 23562 users info\n"
     ]
    }
   ],
   "source": [
    "ALL_USERS = df1.index.unique()\n",
    "print('We will train with', len(ALL_USERS) ,'users info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 4,\n",
    "    'alpha': 8,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"FEATURES_Q.csv\", \"r\") as f:\n",
    "    FEATURES_Q = [f.readline().split() for i in range(1,19)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "#########################\n",
      "\n",
      "#########################\n",
      "### Fold 2\n",
      "#########################\n",
      "\n",
      "#########################\n",
      "### Fold 3\n",
      "#########################\n",
      "\n",
      "#########################\n",
      "### Fold 4\n",
      "#########################\n",
      "\n",
      "#########################\n",
      "### Fold 5\n",
      "#########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "for q in range(1, 19):\n",
    "    print(q)\n",
    "    # USE THIS TRAIN DATA WITH THESE QUESTIONS\n",
    "    FEATURES = FEATURES_Q[q-1]\n",
    "    if q <= 3:\n",
    "        grp = '0-4'\n",
    "        df = df1\n",
    "    elif q <= 13:\n",
    "        grp = '5-12'\n",
    "        df = df2\n",
    "    elif q <= 22:\n",
    "        grp = '13-22'\n",
    "        df = df3\n",
    "\n",
    "    # TRAIN DATA\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        df_train = df.iloc[train_idx] #.reset_index(drop=True)\n",
    "        train_users = df_train.index.values\n",
    "        train_y = targets[targets['session'].isin(list(train_users))].loc[targets.q == q].set_index('session')\n",
    "\n",
    "        df_val = df.iloc[val_idx] #.reset_index(drop=True)\n",
    "        val_users = df_val.index.values\n",
    "        val_y = targets[targets['session'].isin(list(val_users))].loc[targets.q == q].set_index('session')\n",
    "\n",
    "        clf = LGBMClassifier(**lgb_params)\n",
    "        clf.fit(df_train[FEATURES].astype('float32'), train_y['correct'], verbose=0)\n",
    "\n",
    "        clf.booster_.save_model(f'LGBM_question{q}_fold{fold}.lgb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jo_wilder_310 as jo_wilder\n",
    "try:\n",
    "    env = jo_wilder.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    print(\"env made!\")\n",
    "except:\n",
    "    jo_wilder.make_env.__called__ = False\n",
    "    type(env)._state = type(type(env)._state).__dict__['INIT']\n",
    "    env = jo_wilder.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    print(\"env re made!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [[Booster(model_file = f\"/kaggle/working/LGBM_question{q}_fold{fold}.lgb\"\n",
    ") for fold in range(5)] for q in range(1, 19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPreparedFeatures(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values(by=['session_id', 'elapsed_time'])\n",
    "    df[\"full_event_name\"] = df[\"name\"].astype(\"str\") + \"_\" + df[\"event_name\"].astype(\"str\")\n",
    "\n",
    "    df[\"delta_absolute_coor_x\"] = (df[\"room_coor_x\"] + df[\"screen_coor_x\"]).diff(1).fillna(0)\n",
    "    df[\"delta_absolute_coor_y\"] = (df[\"room_coor_y\"] + df[\"screen_coor_y\"]).diff(1).fillna(0)\n",
    "\n",
    "    df[\"radius_absolute_coor\"] = np.sqrt(df[\"delta_absolute_coor_x\"]**2 + df[\"delta_absolute_coor_y\"]**2)\n",
    "    df[\"tangent_absolute_coor\"] = df[\"delta_absolute_coor_y\"]/df[\"delta_absolute_coor_x\"]\n",
    "\n",
    "    df[\"page\"] = df[\"page\"].fillna(-1) + 1\n",
    "    df[\"hover_duration\"] = df[\"hover_duration\"].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "grps = {'0-4':'0_4', '5-12':'5_12', '13-22':'13_22'}\n",
    "\n",
    "count = 0\n",
    "thresh = 0.62\n",
    "\n",
    "samples = []\n",
    "\n",
    "for (test, sample_submission) in iter_test:\n",
    "    samples.append(sample_submission)\n",
    "    grp = test.level_group.values[0]\n",
    "    a,b = limits[grp]\n",
    "    \n",
    "    test = createPreparedFeatures(test)\n",
    "    test = pipeline(test, grps[grp])\n",
    "    \n",
    "    for q in range(a,b):\n",
    "        FEATURES = FEATURES_Q[q-1]\n",
    "        \n",
    "        model_0 = models_list[q-1][0]\n",
    "        model_1 = models_list[q-1][1]\n",
    "        model_2 = models_list[q-1][2]\n",
    "        model_3 = models_list[q-1][3]\n",
    "        model_4 = models_list[q-1][4]\n",
    "        \n",
    "        pred_0 = model_0.predict(test[FEATURES].astype(np.float32))\n",
    "        pred_1 = model_1.predict(test[FEATURES].astype(np.float32))\n",
    "        pred_2 = model_2.predict(test[FEATURES].astype(np.float32))\n",
    "        pred_3 = model_3.predict(test[FEATURES].astype(np.float32))\n",
    "        pred_4 = model_4.predict(test[FEATURES].astype(np.float32))\n",
    "        \n",
    "        pred = (pred_0 + pred_1 + pred_2 + pred_3 + pred_4) / 5\n",
    "        mask = sample_submission.session_id.str.contains(f'q{q}')\n",
    "        sample_submission.loc[mask,'correct'] = int( pred > thresh)\n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('submission.csv')\n",
    "print( df.shape )\n",
    "df.head(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
